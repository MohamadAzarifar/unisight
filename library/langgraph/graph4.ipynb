{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ec583a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.detect the language of the question\n",
    "# 2.get approval of the detected language from the user\n",
    "# 3.get the question from the user as input\n",
    "# 4.translate the question to english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163bb0f5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "72678f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END, START\n",
    "from typing import TypedDict, List, Annotated\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "import operator\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import re\n",
    "from langchain_ollama import ChatOllama\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4467afee",
   "metadata": {},
   "source": [
    "# States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6d7c9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class States(TypedDict):\n",
    "    messages: Annotated[List, operator.add]  # Accumulates all messages\n",
    "    question: str  # Original user query\n",
    "    language: str\n",
    "    approve_language: str\n",
    "    translation: str\n",
    "\n",
    "static_language = \"Tulu\"\n",
    "static_approve_language = \"NO\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2aa764",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "391b2b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_detect_language = \"\"\"\n",
    "Detect the language of the user's text. \n",
    "Respond with ONLY the language name in English. \n",
    "Do not include any other text, explanations, or punctuation.\n",
    "The language is not {language}\n",
    "\n",
    "Examples:\n",
    "- User: \"Hola c√≥mo est√°s\" ‚Üí Spanish\n",
    "- User: \"Bonjour comment √ßa va\" ‚Üí French\n",
    "- User: \"Hello how are you\" ‚Üí English\n",
    "- User: \"Wie geht es dir\" ‚Üí German\n",
    "- User: \"‰Ω†Â•ΩÂêó\" ‚Üí Chinese\n",
    "- User: \"„ÅäÂÖÉÊ∞ó„Åß„Åô„Åã\" ‚Üí Japanese\n",
    "- User: \"–ö–∞–∫ –¥–µ–ª–∞\" ‚Üí Russian\n",
    "- User: \"ÿ≥ŸÑÿßŸÖÿå ÿ≠ÿßŸÑÿ™ ⁄Üÿ∑Ÿàÿ±Ÿá\" ‚Üí Persian\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "628344c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_approval = \"\"\"\n",
    "Analyze the user's response to determine if it means YES or NO.\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. Respond with ONLY \"YES\" or \"NO\" in uppercase letters\n",
    "2. No additional text, explanations, or punctuation\n",
    "3. Consider context, tone, and common expressions\n",
    "4. For ambiguous responses, choose the most probable interpretation\n",
    "\n",
    "YES INDICATORS (respond with YES):\n",
    "- Direct affirmatives: yes, yeah, yep, yup, sure, absolutely, definitely, certainly\n",
    "- Agreement: okay, alright, fine, agreed, of course, by all means\n",
    "- Positive confirmation: correct, right, exactly, that's right, I agree\n",
    "- Enthusiastic: absolutely!, definitely!, without a doubt!, certainly!\n",
    "- Implied yes: \"I think so\", \"probably\", \"maybe\", \"I guess\", \"why not\"\n",
    "\n",
    "NO INDICATORS (respond with NO):\n",
    "- Direct negatives: no, nope, nah, never, not at all, absolutely not\n",
    "- Refusal: I can't, I won't, I don't think so, I'd rather not\n",
    "- Negative confirmation: incorrect, wrong, that's not right, I disagree\n",
    "- Hesitation: not really, not exactly, sort of but not really\n",
    "- Avoidance: maybe later, another time, I'm not sure\n",
    "\n",
    "AMBIGUOUS CASES:\n",
    "- \"I don't know\" ‚Üí NO (unless context suggests otherwise)\n",
    "- \"Maybe\" ‚Üí Consider context, but usually NO for clear decisions\n",
    "- Sarcasm: Interpret literal meaning despite tone\n",
    "\n",
    "Respond with only YES or NO:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a410398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_translate_to_english = \"\"\"\"\n",
    "You are a professional translator. Translate the following text to English.\n",
    "\n",
    "CRITICAL REQUIREMENTS:\n",
    "1. Preserve the original meaning, context, and intent exactly\n",
    "2. Maintain appropriate tone (formal, informal, professional, casual)\n",
    "3. Handle idioms and cultural references appropriately\n",
    "4. Respond with ONLY the English translation, no additional text\n",
    "5. Ensure natural, fluent English output\n",
    "\n",
    "TRANSLATION GUIDELINES:\n",
    "- For questions: Keep the interrogative form\n",
    "- For commands: Maintain imperative tone  \n",
    "- For statements: Preserve declarative nature\n",
    "- Handle politeness markers: \"please\", \"thank you\", honorifics\n",
    "- Translate proper names phonetically when appropriate\n",
    "- Convert currency, measurements, dates to standard formats\n",
    "\n",
    "SPECIAL CASES:\n",
    "- Technical terms: Use standard English equivalents\n",
    "- Slang: Find appropriate English equivalents\n",
    "- Humor/sarcasm: Preserve the intended effect\n",
    "- Ambiguous text: Choose most probable meaning\n",
    "\n",
    "Provide only the English translation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9f2e0",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e13558b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOllama(model=\"llama3.2:3b\", reasoning=False, temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0f129",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2969e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question(state: States) -> States:\n",
    "    \"\"\"Get the question from the user\"\"\"\n",
    "\n",
    "    print(\"‚ö°Ô∏è Getting the question\")\n",
    "\n",
    "    user_input = input(\"How can I help you?\")\n",
    "\n",
    "    print(f\"üì° Question: {user_input}\")\n",
    "\n",
    "    state[\"question\"] = user_input\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7a1c3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(state: States) -> States:\n",
    "    \"\"\"Detect the langugae of the question\"\"\"\n",
    "\n",
    "    print(\"‚ö°Ô∏è Detecting Language...\")\n",
    "\n",
    "    print(f\"‚öôÔ∏è {detect_language.__name__} Step 1: {state.get(\"language\", static_language)}\")\n",
    "    chat = [\n",
    "        SystemMessage(content=prompt_detect_language.format(\n",
    "            language=state[\"language\"]\n",
    "        )),\n",
    "        HumanMessage(content=state[\"question\"])\n",
    "    ]\n",
    "\n",
    "    print(f\"‚öôÔ∏è {detect_language.__name__} Step 2\")\n",
    "    language = llm.invoke(chat).content\n",
    "\n",
    "    print(f\"üì° Language Detected:\\n{language}\")\n",
    "\n",
    "    print(f\"‚öôÔ∏è {detect_language.__name__} Step 3\")\n",
    "\n",
    "    state[\"language\"] = language\n",
    "\n",
    "    return state\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f1bf1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approve_language(state: States) -> States:\n",
    "    \"\"\"Ask user to approve detected language is correct or not\"\"\"\n",
    "\n",
    "    print(\"‚ö°Ô∏è Approving Detected Language...\")\n",
    "\n",
    "    user_input = input(\"Do you confirm detected language?\")\n",
    "\n",
    "    print(f\"‚öôÔ∏è {approve_language.__name__} Step 1: {user_input}\")\n",
    "\n",
    "    chat = [\n",
    "        SystemMessage(content=prompt_approval),\n",
    "        HumanMessage(content=user_input)\n",
    "    ]\n",
    "\n",
    "    approve = llm.invoke(chat).content\n",
    "\n",
    "    print(f\"üì° Approve Language:\\n{approve}\")\n",
    "\n",
    "    state[\"approve_language\"] = approve\n",
    "    \n",
    "    return state\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0b8cbd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_language_approved(state: States) -> States:\n",
    "    \"\"\"Check the detected language is approved by the user\"\"\"\n",
    "\n",
    "    approved = state['approve_language']\n",
    "\n",
    "    print(f\"üí° Is Language Approved: {approved}\")\n",
    "\n",
    "    return approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a508b0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_question(state: States) -> States:\n",
    "    \"\"\"Translate the question to english\"\"\"\n",
    "\n",
    "    print(\"‚ö°Ô∏è Translating Question...\")\n",
    "\n",
    "    chat = [\n",
    "        SystemMessage(content=prompt_translate_to_english),\n",
    "        HumanMessage(content=state[\"question\"])\n",
    "    ]\n",
    "\n",
    "    translation = llm.invoke(chat).content\n",
    "\n",
    "    print(f\"üì° Translated Question is:\\n{translation}\")\n",
    "\n",
    "    state[\"translation\"] = translation\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be73546",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b872b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_workflow():\n",
    "    workflow = StateGraph(States)\n",
    "    \n",
    "    workflow.add_node(get_question.__name__, get_question)\n",
    "    workflow.add_node(detect_language.__name__, detect_language)\n",
    "    workflow.add_node(approve_language.__name__, approve_language)\n",
    "    workflow.add_node(translate_question.__name__, translate_question)\n",
    "    workflow.add_node(\"summerize\", lambda state: state)\n",
    "\n",
    "\n",
    "    workflow.add_edge(START, get_question.__name__)\n",
    "    workflow.add_edge(get_question.__name__, detect_language.__name__)\n",
    "    workflow.add_edge(detect_language.__name__, approve_language.__name__)\n",
    "\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        approve_language.__name__,\n",
    "        is_language_approved,\n",
    "        {\n",
    "            \"YES\": translate_question.__name__,\n",
    "            \"NO\": detect_language.__name__\n",
    "        }\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(translate_question.__name__, \"summerize\")\n",
    "\n",
    "    workflow.add_edge(\"summerize\", END)\n",
    "\n",
    "\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b42ea1",
   "metadata": {},
   "source": [
    "# Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6b9aaea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö°Ô∏è Getting the question\n",
      "üì° Question: ÿ®Ÿáÿ™ÿ±€åŸÜ ŸÖÿ¥ÿ™ÿ±€å\n",
      "‚ö°Ô∏è Detecting Language...\n",
      "‚öôÔ∏è detect_language Step 1: Tulu\n",
      "‚öôÔ∏è detect_language Step 2\n",
      "üì° Language Detected:\n",
      "Persian\n",
      "‚öôÔ∏è detect_language Step 3\n",
      "‚ö°Ô∏è Approving Detected Language...\n",
      "‚öôÔ∏è approve_language Step 1: ÿπÿßŸÑ€å\n",
      "üì° Approve Language:\n",
      "YES\n",
      "üí° Is Language Approved: YES\n",
      "‚ö°Ô∏è Translating Question...\n",
      "üì° Translated Question is:\n",
      "Best customer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [],\n",
       " 'question': 'ÿ®Ÿáÿ™ÿ±€åŸÜ ŸÖÿ¥ÿ™ÿ±€å',\n",
       " 'language': 'Persian',\n",
       " 'approve_language': 'YES',\n",
       " 'translation': 'Best customer'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent = create_workflow()\n",
    "\n",
    "initiate_state = {\n",
    "    \"messages\": [],\n",
    "    \"question\": \"\",\n",
    "    \"language\": static_language,\n",
    "    \"approve_language\": static_approve_language,\n",
    "    \"translation\": \"\"\n",
    "    \n",
    "}\n",
    "\n",
    "agent.invoke(initiate_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
