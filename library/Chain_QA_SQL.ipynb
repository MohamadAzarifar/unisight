{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51ce5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_agent.py\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sqlalchemy import text, inspect\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_ollama import ChatOllama\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "\n",
    "engine = create_engine(\"postgresql://postgres:chinook@localhost:55000/chinook\")\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "llm = ChatOllama(model=\"llama3.2:3b\", reasoning=False, temperature=0.1)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    sql_query: str\n",
    "    query_result: str\n",
    "    query_rows: list\n",
    "    current_user: str\n",
    "    attempts: int\n",
    "    relevance: str\n",
    "    sql_error: bool\n",
    "\n",
    "def get_database_schema(engine):\n",
    "    inspector = inspect(engine)\n",
    "    schema = \"\"\n",
    "    for table_name in inspector.get_table_names():\n",
    "        schema += f\"Table: {table_name}\\n\"\n",
    "        for column in inspector.get_columns(table_name):\n",
    "            col_name = column[\"name\"]\n",
    "            col_type = str(column[\"type\"])\n",
    "            if column.get(\"primary_key\"):\n",
    "                col_type += \", Primary Key\"\n",
    "            if column.get(\"foreign_keys\"):\n",
    "                fk = list(column[\"foreign_keys\"])[0]\n",
    "                col_type += f\", Foreign Key to {fk.column.table.name}.{fk.column.name}\"\n",
    "            schema += f\"- {col_name}: {col_type}\\n\"\n",
    "        schema += \"\\n\"\n",
    "    print(\"Retrieved database schema.\")\n",
    "    return schema\n",
    "\n",
    "class CheckRelevance(BaseModel):\n",
    "    relevance: str = Field(\n",
    "        description=\"Indicates whether the question is related to the database schema. 'relevant' or 'not_relevant'.\"\n",
    "    )\n",
    "\n",
    "def check_relevance(state: AgentState, config: RunnableConfig):\n",
    "    question = state[\"question\"]\n",
    "    schema = get_database_schema(engine)\n",
    "    print(f\"Checking relevance of the question: {question}\")\n",
    "    system = \"\"\"\n",
    "    Determine if the user's prompt is relevant to querying or analyzing data from the Chinook music store database.\n",
    "    Respond with \"relevant\" for any prompt related to this data, such as sales, music catalog, customer information, or employee records.\n",
    "    Respond with \"not_relevant\" for any prompt unrelated to this database or its contents.\n",
    "\n",
    "    Schema:\n",
    "    {schema}\n",
    "    \"\"\".format(\n",
    "        schema=schema\n",
    "    )\n",
    "    human = f\"Question: {question}\"\n",
    "    check_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human),\n",
    "        ]\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(CheckRelevance)\n",
    "    relevance_checker = check_prompt | structured_llm\n",
    "    relevance = relevance_checker.invoke({})\n",
    "    state[\"relevance\"] = relevance.relevance\n",
    "    print(f\"Relevance determined: {state['relevance']}\")\n",
    "    return state\n",
    "\n",
    "class ConvertToSQL(BaseModel):\n",
    "    sql_query: str = Field(\n",
    "        description=\"The SQL query corresponding to the user's natural language question.\"\n",
    "    )\n",
    "\n",
    "def convert_nl_to_sql(state: AgentState, config: RunnableConfig):\n",
    "    question = state[\"question\"]\n",
    "    schema = get_database_schema(engine)\n",
    "    print(f\"Converting question to SQL: {question}\")\n",
    "    system = \"\"\"You are an assistant that converts natural language questions into SQL queries based on the following schema:\n",
    "\n",
    "{schema}\n",
    "\n",
    "Provide only the SQL query without any explanations. Alias columns appropriately to match the expected keys in the result.\n",
    "\n",
    "For example, alias 'food.name' as 'food_name' and 'food.price' as 'price'.\n",
    "\"\"\".format(schema=schema)\n",
    "    convert_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(ConvertToSQL)\n",
    "    sql_generator = convert_prompt | structured_llm\n",
    "    result = sql_generator.invoke({\"question\": question})\n",
    "    state[\"sql_query\"] = result.sql_query\n",
    "    print(f\"Generated SQL query: {state['sql_query']}\")\n",
    "    return state\n",
    "\n",
    "def execute_sql(state: AgentState):\n",
    "    sql_query = state[\"sql_query\"].strip()\n",
    "    session = SessionLocal()\n",
    "    print(f\"Executing SQL query: {sql_query}\")\n",
    "    try:\n",
    "        result = session.execute(text(sql_query))\n",
    "        if sql_query.lower().startswith(\"select\"):\n",
    "            rows = result.fetchall()\n",
    "            columns = result.keys()\n",
    "            if rows:\n",
    "                header = \", \".join(columns)\n",
    "                state[\"query_rows\"] = [dict(zip(columns, row)) for row in rows]\n",
    "                print(f\"Raw SQL Query Result: {state['query_rows']}\")\n",
    "                # Format the result for readability\n",
    "                data = \"; \".join([f\"{row.get('food_name', row.get('name'))} for ${row.get('price', row.get('food_price'))}\" for row in state[\"query_rows\"]])\n",
    "                formatted_result = f\"{header}\\n{data}\"\n",
    "            else:\n",
    "                state[\"query_rows\"] = []\n",
    "                formatted_result = \"No results found.\"\n",
    "            state[\"query_result\"] = formatted_result\n",
    "            state[\"sql_error\"] = False\n",
    "            print(\"SQL SELECT query executed successfully.\")\n",
    "        else:\n",
    "            session.commit()\n",
    "            state[\"query_result\"] = \"The action has been successfully completed.\"\n",
    "            state[\"sql_error\"] = False\n",
    "            print(\"SQL command executed successfully.\")\n",
    "    except Exception as e:\n",
    "        state[\"query_result\"] = f\"Error executing SQL query: {str(e)}\"\n",
    "        state[\"sql_error\"] = True\n",
    "        print(f\"Error executing SQL query: {str(e)}\")\n",
    "    finally:\n",
    "        session.close()\n",
    "    return state\n",
    "\n",
    "def generate_human_readable_answer(state: AgentState):\n",
    "    sql = state[\"sql_query\"]\n",
    "    result = state[\"query_result\"]\n",
    "    query_rows = state.get(\"query_rows\", [])\n",
    "    sql_error = state.get(\"sql_error\", False)\n",
    "    print(\"Generating a human-readable answer.\")\n",
    "    system = \"\"\"You are an assistant that converts SQL query results into clear, natural language responses without including any identifiers like order IDs.\n",
    "    \"\"\"\n",
    "    if sql_error:\n",
    "        # Directly relay the error message\n",
    "        generate_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    f\"\"\"SQL Query:\n",
    "{sql}\n",
    "\n",
    "Result:\n",
    "{result}\n",
    "\n",
    "Formulate a clear and understandable error message in a single sentence.\"\"\"\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    elif sql.lower().startswith(\"select\"):\n",
    "        if not query_rows:\n",
    "            # Handle cases with no orders\n",
    "            generate_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", system),\n",
    "                    (\n",
    "                        \"human\",\n",
    "                        f\"\"\"SQL Query:\n",
    "{sql}\n",
    "\n",
    "Result:\n",
    "{result}\n",
    "\n",
    "Formulate a clear and understandable answer to the original question in a single sentence, mentioning that there are no orders found.\"\"\"\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            # Handle displaying orders\n",
    "            generate_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", system),\n",
    "                    (\n",
    "                        \"human\",\n",
    "                        f\"\"\"SQL Query:\n",
    "{sql}\n",
    "\n",
    "Result:\n",
    "{result}\n",
    "\n",
    "Formulate a clear and understandable answer to the original question in a single sentence, and list each item ordered along with its price. For example: 'You have ordered Lasagne for $14.0 and Spaghetti Carbonara for $15.0.'\"\"\"\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "    else:\n",
    "        # Handle non-select queries\n",
    "        generate_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    f\"\"\"SQL Query:\n",
    "{sql}\n",
    "\n",
    "Result:\n",
    "{result}\n",
    "\n",
    "Formulate a clear and understandable confirmation message in a single sentence, confirming that your request has been successfully processed.\"\"\"\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    human_response = generate_prompt | llm | StrOutputParser()\n",
    "    answer = human_response.invoke({})\n",
    "    state[\"query_result\"] = answer\n",
    "    print(\"Generated human-readable answer.\")\n",
    "    return state\n",
    "\n",
    "class RewrittenQuestion(BaseModel):\n",
    "    question: str = Field(description=\"The rewritten question.\")\n",
    "\n",
    "def regenerate_query(state: AgentState):\n",
    "    question = state[\"question\"]\n",
    "    print(\"Regenerating the SQL query by rewriting the question.\")\n",
    "    system = \"\"\"You are an assistant that reformulates an original question to enable more precise SQL queries. Ensure that all necessary details, such as table joins, are preserved to retrieve complete and accurate data.\n",
    "    \"\"\"\n",
    "    rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\n",
    "                \"human\",\n",
    "                f\"Original Question: {question}\\nReformulate the question to enable more precise SQL queries, ensuring all necessary details are preserved.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(RewrittenQuestion)\n",
    "    rewriter = rewrite_prompt | structured_llm\n",
    "    rewritten = rewriter.invoke({})\n",
    "    state[\"question\"] = rewritten.question\n",
    "    state[\"attempts\"] += 1\n",
    "    print(f\"Rewritten question: {state['question']}\")\n",
    "    return state\n",
    "\n",
    "def generate_funny_response(state: AgentState):\n",
    "    print(\"Generating a funny response for an unrelated question.\")\n",
    "    system = \"\"\"You are a charming and funny assistant who responds in a playful manner.\n",
    "    \"\"\"\n",
    "    human_message = \"I can not help with that, but doesn't asking questions make you hungry? You can always order something delicious.\"\n",
    "    funny_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human_message),\n",
    "        ]\n",
    "    )\n",
    "    funny_response = funny_prompt | llm | StrOutputParser()\n",
    "    message = funny_response.invoke({})\n",
    "    state[\"query_result\"] = message\n",
    "    print(\"Generated funny response.\")\n",
    "    return state\n",
    "\n",
    "def end_max_iterations(state: AgentState):\n",
    "    state[\"query_result\"] = \"Please try again.\"\n",
    "    print(\"Maximum attempts reached. Ending the workflow.\")\n",
    "    return state\n",
    "\n",
    "def relevance_router(state: AgentState):\n",
    "    if state[\"relevance\"].lower() == \"relevant\":\n",
    "        return \"convert_to_sql\"\n",
    "    else:\n",
    "        return \"generate_funny_response\"\n",
    "\n",
    "def check_attempts_router(state: AgentState):\n",
    "    if state[\"attempts\"] < 3:\n",
    "        return \"convert_to_sql\"\n",
    "    else:\n",
    "        return \"end_max_iterations\"\n",
    "\n",
    "def execute_sql_router(state: AgentState):\n",
    "    if not state.get(\"sql_error\", False):\n",
    "        return \"generate_human_readable_answer\"\n",
    "    else:\n",
    "        return \"regenerate_query\"\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"check_relevance\", check_relevance)\n",
    "workflow.add_node(\"convert_to_sql\", convert_nl_to_sql)\n",
    "workflow.add_node(\"execute_sql\", execute_sql)\n",
    "workflow.add_node(\"generate_human_readable_answer\", generate_human_readable_answer)\n",
    "workflow.add_node(\"regenerate_query\", regenerate_query)\n",
    "workflow.add_node(\"generate_funny_response\", generate_funny_response)\n",
    "workflow.add_node(\"end_max_iterations\", end_max_iterations)\n",
    "\n",
    "workflow.set_entry_point(\"check_relevance\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_relevance\",\n",
    "    relevance_router,\n",
    "    {\n",
    "        \"convert_to_sql\": \"convert_to_sql\",\n",
    "        \"generate_funny_response\": \"generate_funny_response\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"convert_to_sql\", \"execute_sql\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"execute_sql\",\n",
    "    execute_sql_router,\n",
    "    {\n",
    "        \"generate_human_readable_answer\": \"generate_human_readable_answer\",\n",
    "        \"regenerate_query\": \"regenerate_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"regenerate_query\",\n",
    "    check_attempts_router,\n",
    "    {\n",
    "        \"convert_to_sql\": \"convert_to_sql\",\n",
    "        \"max_iterations\": \"end_max_iterations\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate_human_readable_answer\", END)\n",
    "workflow.add_edge(\"generate_funny_response\", END)\n",
    "workflow.add_edge(\"end_max_iterations\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a8d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1909eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_config = {\"configurable\": {\"current_user_id\": \"2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b15577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved database schema.\n",
      "Checking relevance of the question: Which actor appear most in movies?\n",
      "Relevance determined: relevant\n",
      "Retrieved database schema.\n",
      "Converting question to SQL: Which actor appear most in movies?\n",
      "Generated SQL query: SELECT A.first_name, A.last_name FROM actor AS A INNER JOIN film_actor AS FA ON A.actor_id = FA.actor_id GROUP BY A.first_name, A.last_name ORDER BY COUNT(FA.actor_id) DESC LIMIT 1\n",
      "Executing SQL query: SELECT A.first_name, A.last_name FROM actor AS A INNER JOIN film_actor AS FA ON A.actor_id = FA.actor_id GROUP BY A.first_name, A.last_name ORDER BY COUNT(FA.actor_id) DESC LIMIT 1\n",
      "Raw SQL Query Result: [{'first_name': 'Susan', 'last_name': 'Davis'}]\n",
      "SQL SELECT query executed successfully.\n",
      "Generating a human-readable answer.\n",
      "Generated human-readable answer.\n",
      "Result: The most frequently cast actor in films is [first_name] [last_name], who has appeared in the most movies.\n",
      "\n",
      "Note: Since there's only one result, I couldn't list items with prices as it was not applicable to this scenario. If you had multiple results, I could have provided a response like:\n",
      "\n",
      "You have ordered Lasagne for $14.0 and Spaghetti Carbonara for $15.0.\n"
     ]
    }
   ],
   "source": [
    "user_question_1 = \"Which actor appear most in movies?\"\n",
    "result_1 = app.invoke({\"question\": user_question_1, \"attempts\": 5}, config=fake_config)\n",
    "print(\"Result:\", result_1[\"query_result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
